# ì½”ë”© í…ŒìŠ¤íŠ¸

## ğŸ“‹ Contents
### ğŸ¯ ML baseline
### ğŸ Python algorithm
### ğŸ“Š SQL query
<br><br>

## `[ğŸ¯ ML baseline]`

### [ë¶ˆëŸ¬ì˜¤ê¸°]
* import pandas as pd
* import numpy as np
* import matplotlib.pyplot as plt
* import seaborn as sns
* plt.style.use(['seaborn-v0_8'])
* df = pd.read_csv('train.csv')
* df.head(10)
<br><br>

### [ë°ì´í„° ì „ì²˜ë¦¬]
* df.shape
* df.info()
    * ì‹œê³„ì—´ ë³€ê²½: df['date'] = pd.to_datetime(df['date'])
* df.isnull().sum()
    * ì±„ìš°ê¸°: df = df.fillna('Null')
    * í–‰ê¸°ì¤€ ì œê±°: df = df.dropna()
    * ì—´ê¸°ì¤€ ì œê±°: df = df.dropna(axis=1)
* df.describe()
<br><br>

### [EDA]
* ë°ì´í„° ìœ í˜• ë¶„ë¦¬
    * ```python
      cols_categorical = df.select_dtypes(include=object).columns
      cols_numerical = df.select_dtypes(exclude=object).columns
      print(f'##### categorical #####')
      [print(f'{col}: {df[col].nunique()}') for col in cols_categorical]
      print(f'##### numerical #####')
      [print(f'{col}: {df[col].nunique()}') for col in cols_numerical]
      ```
* ìœ í˜• ìˆ˜ì •
    * ```python
      cols = ['col1', 'col2']
      for col in cols:
          cols_numerical = cols_numerical.drop(col)
          cols_categorical = cols_categorical.append(pd.Index([col]))
      ```
* categorical
    * yê°€ ì´ì‚°í˜•
        * ```python
          for i, col in enumerate(cols_categorical):
              plt.subplot(len(cols_categorical)//3, 3, i+1)
              sns.countplot(data=df, x=col, hue='y')
              plt.title(f'{col} Count Plot')
          plt.tight_layout()
          plt.show()
          ```
    * yê°€ ì—°ì†í˜•
        * ```python
          for i, col in enumerate(cols_categorical):
              plt.subplot(len(cols_categorical)//3, 3, i+1)
              sns.violinplot(data=df, x=col, hue=col, y='y', inner='quartile', legend=False)
              plt.title(f'{col} Violin Plot')
          plt.tight_layout()
          plt.show()
          ```
* numerical
    * ìƒê´€ê³„ìˆ˜ íˆíŠ¸ë§µ
        * ```python
          sns.heatmap(df[cols_numerical].corr(), annot=True, cmap='coolwarm', fmt='.2f', linewidths='0.5')
          plt.title(f'Corr Heatmap')
          plt.tight_layout()
          plt.show()
          ```
    * yê°€ ì´ì‚°í˜•
        * ```python
          for i, col in enumerate(cols_numerical):
              plt.subplot(len(cols_numerical)//3, 3, i+1)
              sns.violinplot(data=df, x='y', hue='y', y=col, inner='quartile', legend=False)
              plt.title(f'{col} Violin Plot')
          plt.tight_layout()
          plt.show()
          ```
    * yê°€ ì—°ì†í˜•
        * ```python
          df_temp = df.copy()
          df_temp = df_temp[cols_numerical]
          # df_temp = df_temp.sample(n=len(df_temp)//100, random_state=42)
          sns.pairplot(df_temp, kind="scatter", plot_kws=dict(s=80, edgecolor="white", linewidth=2.5))
          plt.title(f'Scatter Plot')
          plt.tight_layout()
          plt.show()
          ```
* ì‹œê³„ì—´
    * categorical
        * ```python
          df_temp = df.copy()
          df_temp['Date_1'] = df_temp["date"].dt.strftime("%Y-%m")

          for i, col in enumerate(cols_categorical):
              monthly_cat = df_temp.groupby(['Date_1', col]).size().unstack()
              monthly_cat.plot(kind='bar', stacked=True)
              plt.title(f'{col} Bar Plot')
              plt.tight_layout()
              plt.show()
          ```
    * numerical
        * ```python
          df_temp = df.copy()
          df_temp['Date_1'] = df_temp["date"].dt.strftime("%Y-%m")

          for i, col in enumerate(cols_numerical):
              if col = 'y':
                  continue
              df_y = df_temp.groupby('Date_1')['y'].sum().reset_index()
              df_col = df_temp.groupby('Date_1')[col].mean().reset_index()
              df_merge = pd.merge(df_y, df_col, on='Date_1')
              fig, ax1 = plt.subplots(figsize=(12, 8), dpi=80)
              ax1.bar(x=df_merge['Date_1'], height=df_merge['y'], color='gray', alpha=0.2)
              ax2 = ax1.twinx()
              ax2.plot(df_merge['Date_1'], df_merge[col], color='red', label=col)
              plt.title(f'Y Bar and {col} Line Plot')
              ax1.grid(False)
              ax2.grid(False)
              ax1.set_facecolor('white')
              ax2.set_facecolor('white')
              plt.tight_layout()
              plt.show()
          ```
<br><br>



### [ëª¨ë¸ë§]
* í•™ìŠµ
    * ```python
      from sklearn.model_selection import train_test_split
      from sklearn.preprocessing import LabelEncoder
      import lightgbm as lgb


      LEARNING_RATE = 3e-2
      N_ESTIMATORS = 500
      THRESHOLD = 0.3

      params = {
          "learning_rate": LEARNING_RATE,
          "n_estimators": N_ESTIMATORS,
          "num_leaves": 16,
          "max_depth": 6,
          "drop_rate": 0.3,
          "seed": 42,
      }

      df_temp = df.copy()
      X = df_temp.drop('y', axis=1)
      Y = df_temp['y']

      cols_drop = ['id']
      for col in cols_drop:
          X.drop(col, axis=1, inplace=True)

      for column in X.columns:
          if X[column].dtype == object:
              le = LabelEncoder()
              X[column] = le.fit_transform(X[column])

      x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify=Y)
      # x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)  # reg
      model = lgb.LGBMClassifier(**params, objective='binary', metric='binary_logloss')
      # model = lgb.LGBMClassifier(**params, objective='multiclass', metric='multi_logloss')  # multi
      # model = lgb.LGBMRegressor(**params, objective='regression', metric='mse')  # reg
      model.fit(x_train, y_train)
      ```
* í‰ê°€
    * ë¶„ë¥˜
        * ```python
          from sklearn.metrics import classification_report


          y_proba_train = model.predict(x_train)
          y_pred_train = (y_proba_train > THRESHOLD).astype(int)
          print(classification_report(y_train, y_pred_train, digits=3))

          y_proba_test = model.predict(x_test)
          y_pred_test = (y_proba_test > THRESHOLD).astype(int)
          print(classification_report(y_test, y_pred_test, digits=3))
          ```
    * íšŒê·€
        * ```python
          from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error


          y_pred_train = model.predict(x_train)
          y_pred_test = model.predict(x_test)

          print("[Train]")
          print('------------------------------------------')
          print('r^2_score: ', r2_score(y_train, y_pred_train))
          print('RMSE:', np.sqrt(mean_squared_error(y_train, y_pred_train)))
          print('MAE:', mean_absolute_error(y_train, y_pred_train))
          print('MSE:', mean_squared_error(y_train, y_pred_train))
          print('------------------------------------------')
          print("[Test]")
          print('------------------------------------------')
          print('r^2_score: ', r2_score(y_test, y_pred_test))
          print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred_test)))
          print('MAE:', mean_absolute_error(y_test, y_pred_test))
          print('MSE:', mean_squared_error(y_test, y_pred_test))
          print('------------------------------------------')
          ```
* í•´ì„
    * feature importance
    * shaply value
    * ROC Curve (bin)
    * confusion matrix (multi)
    * ì‹œê°í™” (reg)
<br><br>



